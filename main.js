/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// main.ts
var main_exports = {};
__export(main_exports, {
  default: () => VoiceWritingPlugin
});
module.exports = __toCommonJS(main_exports);
var import_obsidian3 = require("obsidian");

// src/constants.ts
var MODELS = {
  openai: "whisper-1",
  groq: "whisper-large-v3"
};
var API_ENDPOINTS = {
  openai: "https://api.openai.com/v1/audio/transcriptions",
  groq: "https://api.groq.com/openai/v1/audio/transcriptions"
};
var API_TEST_ENDPOINTS = {
  openai: "https://api.openai.com/v1/models",
  groq: "https://api.groq.com/openai/v1/models"
};
var API_CONFIG = {
  TIMEOUT_MS: 3e4,
  // 30 seconds
  MAX_FILE_SIZE_MB: 25,
  AUDIO_MIME_TYPE: "audio/webm"
};
var SUPPORTED_LANGUAGES = [
  { code: "auto", name: "Auto Detect" },
  { code: "en", name: "English" },
  { code: "ko", name: "Korean (\uD55C\uAD6D\uC5B4)" },
  { code: "ja", name: "Japanese (\u65E5\u672C\u8A9E)" },
  { code: "zh", name: "Chinese (\u4E2D\u6587)" },
  { code: "es", name: "Spanish (Espa\xF1ol)" },
  { code: "fr", name: "French (Fran\xE7ais)" },
  { code: "de", name: "German (Deutsch)" }
];
var ERROR_MESSAGES = {
  API_KEY_MISSING: "API Key is missing. Please set it in settings.",
  API_KEY_INVALID_FORMAT: (provider) => `Invalid API key format for ${provider}. Please check your API key.`,
  TRANSCRIPTION_FAILED: "Transcription failed. Check console for details.",
  TRANSCRIPTION_TIMEOUT: "Transcription timed out. Please try again.",
  MICROPHONE_PERMISSION_DENIED: "Microphone access denied. Please allow microphone access in your browser/system settings.",
  MICROPHONE_NOT_FOUND: "No microphone found. Please connect a microphone and try again.",
  MICROPHONE_GENERAL_ERROR: "Failed to access microphone. Please check your audio settings.",
  NO_ACTIVE_RECORDING: "No active recording to stop.",
  API_UNAUTHORIZED: "Incorrect API Key (401). Please check your settings.",
  API_QUOTA_EXCEEDED: "API Quota Exceeded (429). Please check your plan."
};
var SUCCESS_MESSAGES = {
  RECORDING_STARTED: "\u{1F399}\uFE0F Recording started...",
  TRANSCRIPTION_COMPLETE: "\u2705 Transcription complete!",
  SETTINGS_SAVED: (service, lang) => `Settings saved: ${service} / ${lang}`,
  COPIED_TO_CLIPBOARD: "Text copied to clipboard (No active editor)",
  API_KEY_VALID: "\u2705 API Key is valid!",
  API_KEY_TEST_START: "\u{1F504} Testing API Key..."
};
var API_TEST_ERRORS = {
  INVALID_KEY: "\u274C Invalid API Key. Please check and try again.",
  QUOTA_EXCEEDED: "\u26A0\uFE0F API Quota exceeded. Check your billing.",
  NETWORK_ERROR: "\u274C Network error. Check your internet connection.",
  UNKNOWN_ERROR: "\u274C Test failed. Check console for details."
};

// src/recorder.ts
var MicrophoneRecorder = class {
  constructor() {
    this.mediaRecorder = null;
    this.audioChunks = [];
  }
  async startRecording() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      this.mediaRecorder = new MediaRecorder(stream);
      this.audioChunks = [];
      this.mediaRecorder.addEventListener("dataavailable", (event) => {
        this.audioChunks.push(event.data);
      });
      this.mediaRecorder.start();
    } catch (error) {
      console.error("Error starting recording:", error);
      throw this.parseMediaError(error);
    }
  }
  async stopRecording() {
    return new Promise((resolve, reject) => {
      if (!this.mediaRecorder) {
        reject(new Error(ERROR_MESSAGES.NO_ACTIVE_RECORDING));
        return;
      }
      this.mediaRecorder.addEventListener("stop", () => {
        var _a;
        const audioBlob = new Blob(this.audioChunks, { type: "audio/webm" });
        this.audioChunks = [];
        (_a = this.mediaRecorder) == null ? void 0 : _a.stream.getTracks().forEach((track) => track.stop());
        this.mediaRecorder = null;
        resolve(audioBlob);
      });
      this.mediaRecorder.stop();
    });
  }
  isRecording() {
    var _a;
    return ((_a = this.mediaRecorder) == null ? void 0 : _a.state) === "recording";
  }
  /**
   * Parse media device errors and provide user-friendly messages
   */
  parseMediaError(error) {
    if (error instanceof DOMException) {
      switch (error.name) {
        case "NotAllowedError":
        case "PermissionDeniedError":
          return {
            type: "permission_denied",
            message: ERROR_MESSAGES.MICROPHONE_PERMISSION_DENIED,
            originalError: error
          };
        case "NotFoundError":
        case "DevicesNotFoundError":
          return {
            type: "not_found",
            message: ERROR_MESSAGES.MICROPHONE_NOT_FOUND,
            originalError: error
          };
        default:
          return {
            type: "general",
            message: ERROR_MESSAGES.MICROPHONE_GENERAL_ERROR,
            originalError: error
          };
      }
    }
    return {
      type: "general",
      message: ERROR_MESSAGES.MICROPHONE_GENERAL_ERROR,
      originalError: error instanceof Error ? error : new Error(String(error))
    };
  }
};

// src/transcription.ts
var import_obsidian = require("obsidian");
var TranscriptionService = class {
  /**
   * Test API key validity by calling the models endpoint
   */
  async testApiKey(apiKey, serviceProvider) {
    var _a, _b;
    if (!apiKey || apiKey.trim().length === 0) {
      return {
        success: false,
        message: API_TEST_ERRORS.INVALID_KEY,
        details: "API key is empty"
      };
    }
    const url = API_TEST_ENDPOINTS[serviceProvider];
    const params = {
      url,
      method: "GET",
      headers: {
        "Authorization": `Bearer ${apiKey.trim()}`
      },
      throw: false
    };
    try {
      const response = await (0, import_obsidian.requestUrl)(params);
      console.log(`API Test Response (${serviceProvider}):`, {
        status: response.status,
        data: response.json
      });
      if (response.status === 200) {
        return {
          success: true,
          message: SUCCESS_MESSAGES.API_KEY_VALID,
          details: `Connected to ${serviceProvider.toUpperCase()} API successfully`
        };
      } else if (response.status === 401) {
        return {
          success: false,
          message: API_TEST_ERRORS.INVALID_KEY,
          details: ((_b = (_a = response.json) == null ? void 0 : _a.error) == null ? void 0 : _b.message) || "Authentication failed"
        };
      } else if (response.status === 429) {
        return {
          success: false,
          message: API_TEST_ERRORS.QUOTA_EXCEEDED,
          details: "Rate limit or quota exceeded"
        };
      } else {
        return {
          success: false,
          message: API_TEST_ERRORS.UNKNOWN_ERROR,
          details: `HTTP ${response.status}: ${JSON.stringify(response.json)}`
        };
      }
    } catch (error) {
      console.error("API Test Error:", error);
      return {
        success: false,
        message: API_TEST_ERRORS.NETWORK_ERROR,
        details: error instanceof Error ? error.message : "Unknown error"
      };
    }
  }
  async transcribe(audioBlob, apiKey, language, serviceProvider) {
    if (!apiKey) {
      new import_obsidian.Notice(ERROR_MESSAGES.API_KEY_MISSING);
      throw new Error("API Key missing");
    }
    if (!this.isValidApiKeyFormat(apiKey, serviceProvider)) {
      new import_obsidian.Notice(ERROR_MESSAGES.API_KEY_INVALID_FORMAT(serviceProvider));
      throw new Error("Invalid API key format");
    }
    const arrayBuffer = await audioBlob.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    const boundary = "----ObsidianVoiceWritingBoundary" + Date.now();
    const body = await this.createFormData(buffer, "recording.webm", boundary, language, serviceProvider);
    const url = API_ENDPOINTS[serviceProvider];
    const params = {
      url,
      method: "POST",
      headers: {
        "Content-Type": `multipart/form-data; boundary=${boundary}`,
        "Authorization": `Bearer ${apiKey}`
      },
      body,
      throw: false
      // Don't throw on non-2xx responses
    };
    try {
      const timeoutPromise = new Promise((_, reject) => {
        setTimeout(() => {
          reject(new Error("TIMEOUT"));
        }, API_CONFIG.TIMEOUT_MS);
      });
      const response = await Promise.race([
        (0, import_obsidian.requestUrl)(params),
        timeoutPromise
      ]);
      if (response.status !== 200) {
        console.error("Transcription failed:", response.json);
        if (response.status === 401) {
          throw new Error("API_UNAUTHORIZED");
        }
        if (response.status === 429) {
          throw new Error("API_QUOTA_EXCEEDED");
        }
        throw new Error(`Transcription failed: ${response.status}`);
      }
      return { text: response.json.text };
    } catch (error) {
      if (error instanceof Error && error.message === "TIMEOUT") {
        console.error("Transcription timeout after", API_CONFIG.TIMEOUT_MS, "ms");
        new import_obsidian.Notice(ERROR_MESSAGES.TRANSCRIPTION_TIMEOUT);
        throw new Error("Transcription timeout");
      }
      console.error("Transcription error:", error);
      new import_obsidian.Notice(ERROR_MESSAGES.TRANSCRIPTION_FAILED);
      throw error;
    }
  }
  isValidApiKeyFormat(apiKey, provider) {
    const trimmedKey = apiKey.trim();
    if (provider === "openai") {
      return trimmedKey.startsWith("sk-") && trimmedKey.length > 20;
    } else if (provider === "groq") {
      return trimmedKey.length > 20 && !/\s/.test(trimmedKey);
    }
    return trimmedKey.length > 10;
  }
  parseErrorResponse(response) {
    var _a;
    try {
      const json = response.json;
      if ((_a = json == null ? void 0 : json.error) == null ? void 0 : _a.message) {
        return {
          status: response.status,
          message: json.error.message,
          details: json.error.type || json.error.code
        };
      }
      return {
        status: response.status,
        message: `HTTP ${response.status} Error`,
        details: JSON.stringify(json)
      };
    } catch (e) {
      return {
        status: response.status,
        message: `HTTP ${response.status} Error`,
        details: "Could not parse error response"
      };
    }
  }
  async createFormData(fileBuffer, fileName, boundary, language, provider) {
    const parts = [];
    const model = MODELS[provider];
    parts.push(Buffer.from(`--${boundary}\r
`));
    parts.push(Buffer.from(`Content-Disposition: form-data; name="file"; filename="${fileName}"\r
`));
    parts.push(Buffer.from(`Content-Type: ${API_CONFIG.AUDIO_MIME_TYPE}\r
\r
`));
    parts.push(fileBuffer);
    parts.push(Buffer.from(`\r
`));
    parts.push(Buffer.from(`--${boundary}\r
`));
    parts.push(Buffer.from(`Content-Disposition: form-data; name="model"\r
\r
`));
    parts.push(Buffer.from(`${model}\r
`));
    if (language && language !== "auto") {
      parts.push(Buffer.from(`--${boundary}\r
`));
      parts.push(Buffer.from(`Content-Disposition: form-data; name="language"\r
\r
`));
      parts.push(Buffer.from(`${language}\r
`));
    }
    parts.push(Buffer.from(`--${boundary}--\r
`));
    return Buffer.concat(parts).buffer;
  }
};

// src/modals.ts
var import_obsidian2 = require("obsidian");
var RecordingModal = class extends import_obsidian2.Modal {
  constructor(app, onStop) {
    super(app);
    this.onStop = onStop;
  }
  onOpen() {
    const { contentEl } = this;
    contentEl.empty();
    contentEl.addClass("voice-writing-recording-modal");
    const container = contentEl.createDiv({ cls: "recording-container" });
    const iconWrapper = container.createDiv({ cls: "recording-icon-wrapper" });
    iconWrapper.createDiv({ cls: "recording-pulse-ring" });
    iconWrapper.createEl("span", { text: "\u{1F399}\uFE0F", cls: "recording-icon" });
    container.createEl("h2", { text: "Recording in Progress..." });
    this.timerEl = container.createDiv({ cls: "recording-timer", text: "00:00" });
    this.startTime = Date.now();
    this.timerInterval = window.setInterval(() => this.updateTimer(), 1e3);
    const btnContainer = container.createDiv({ cls: "recording-controls" });
    const stopBtn = btnContainer.createEl("button", {
      text: "Stop Recording",
      cls: "mod-cta stop-recording-btn"
    });
    stopBtn.onclick = () => {
      this.onStop();
      this.close();
    };
  }
  updateTimer() {
    if (!this.timerEl)
      return;
    const diff = Math.floor((Date.now() - this.startTime) / 1e3);
    const mins = Math.floor(diff / 60).toString().padStart(2, "0");
    const secs = (diff % 60).toString().padStart(2, "0");
    this.timerEl.setText(`${mins}:${secs}`);
  }
  onClose() {
    if (this.timerInterval)
      clearInterval(this.timerInterval);
    this.contentEl.empty();
  }
};
var ProcessingModal = class extends import_obsidian2.Modal {
  constructor(app) {
    super(app);
  }
  onOpen() {
    const { contentEl } = this;
    contentEl.empty();
    contentEl.addClass("voice-writing-processing-modal");
    const container = contentEl.createDiv({ cls: "processing-container" });
    const spinner = container.createDiv({ cls: "voice-writing-spinner" });
    spinner.createDiv({ cls: "double-bounce1" });
    spinner.createDiv({ cls: "double-bounce2" });
    container.createEl("h2", { text: "\u2728 Transcribing..." });
    container.createEl("p", { text: "Sending audio to AI for text conversion." });
    container.createEl("small", { text: "This usually takes a few seconds.", cls: "processing-hint" });
  }
  onClose() {
    const { contentEl } = this;
    contentEl.empty();
  }
};
var QuickOptionModal = class extends import_obsidian2.Modal {
  constructor(app, currentLanguage, currentService, onSelect) {
    super(app);
    this.currentLanguage = currentLanguage;
    this.currentService = currentService;
    this.onSelect = onSelect;
  }
  onOpen() {
    const { contentEl } = this;
    contentEl.empty();
    contentEl.createEl("h2", { text: "Voice Writing Options" });
    let tempLanguage = this.currentLanguage;
    let tempService = this.currentService;
    new import_obsidian2.Setting(contentEl).setName("Language").setDesc("Select audio language").addDropdown((drop) => {
      SUPPORTED_LANGUAGES.forEach((lang) => {
        drop.addOption(lang.code, lang.name);
      });
      drop.setValue(tempLanguage).onChange((value) => tempLanguage = value);
    });
    new import_obsidian2.Setting(contentEl).setName("Service").setDesc("Transcription provider").addDropdown(
      (drop) => drop.addOption("openai", "OpenAI Whisper").addOption("groq", "Groq (Fast)").setValue(tempService).onChange((value) => tempService = value)
    );
    new import_obsidian2.Setting(contentEl).addButton(
      (btn) => btn.setButtonText("Apply").setCta().onClick(() => {
        this.onSelect(tempLanguage, tempService);
        this.close();
      })
    );
  }
  onClose() {
    this.contentEl.empty();
  }
};

// main.ts
var DEFAULT_SETTINGS = {
  apiKey: "",
  language: "auto",
  serviceProvider: "openai"
};
var VoiceWritingPlugin = class extends import_obsidian3.Plugin {
  constructor() {
    super(...arguments);
    this.recordingModal = null;
  }
  async onload() {
    await this.loadSettings();
    this.recorder = new MicrophoneRecorder();
    this.transcriptionService = new TranscriptionService();
    this.ribbonIconEl = this.addRibbonIcon("mic", "Voice Writing", (evt) => {
      this.toggleRecording();
    });
    this.ribbonIconEl.addClass("voice-writing-ribbon");
    this.statusBarItem = this.addStatusBarItem();
    this.updateStatusBar("Idle");
    this.statusBarItem.onClickEvent(() => {
      this.toggleRecording();
    });
    this.addCommand({
      id: "start-recording",
      name: "Start Recording",
      callback: () => this.startRecording()
    });
    this.addCommand({
      id: "stop-recording",
      name: "Stop Recording",
      callback: () => this.stopRecording()
    });
    this.addCommand({
      id: "quick-options",
      name: "Quick Options",
      callback: () => {
        new QuickOptionModal(this.app, this.settings.language, this.settings.serviceProvider, async (lang, service) => {
          this.settings.language = lang;
          this.settings.serviceProvider = service;
          await this.saveSettings();
          new import_obsidian3.Notice(SUCCESS_MESSAGES.SETTINGS_SAVED(service, lang));
        }).open();
      }
    });
    this.addSettingTab(new VoiceWritingSettingTab(this.app, this));
  }
  async toggleRecording() {
    if (this.recorder.isRecording()) {
      await this.stopRecording();
    } else {
      await this.startRecording();
    }
  }
  async startRecording() {
    try {
      await this.recorder.startRecording();
      new import_obsidian3.Notice(SUCCESS_MESSAGES.RECORDING_STARTED);
      this.ribbonIconEl.addClass("voice-writing-recording");
      this.updateStatusBar("Recording...");
      this.recordingModal = new RecordingModal(this.app, () => {
        this.stopRecording();
      });
      this.recordingModal.open();
    } catch (error) {
      const recordingError = error;
      if (recordingError && recordingError.type) {
        new import_obsidian3.Notice(recordingError.message);
      } else {
        new import_obsidian3.Notice(ERROR_MESSAGES.MICROPHONE_GENERAL_ERROR);
      }
      console.error("Recording error:", error);
    }
  }
  async stopRecording() {
    if (this.recordingModal) {
      this.recordingModal.close();
      this.recordingModal = null;
    }
    try {
      const blob = await this.recorder.stopRecording();
      this.ribbonIconEl.removeClass("voice-writing-recording");
      this.updateStatusBar("Processing...");
      const processingModal = new ProcessingModal(this.app);
      processingModal.open();
      const fileName = `recording-${Date.now()}.webm`;
      const arrayBuffer = await blob.arrayBuffer();
      await this.app.vault.createBinary(fileName, new Uint8Array(arrayBuffer));
      try {
        const result = await this.transcriptionService.transcribe(
          blob,
          this.settings.apiKey,
          this.settings.language,
          this.settings.serviceProvider
        );
        processingModal.close();
        new import_obsidian3.Notice(SUCCESS_MESSAGES.TRANSCRIPTION_COMPLETE);
        this.updateStatusBar("Idle");
        const activeView = this.app.workspace.getActiveViewOfType(import_obsidian3.MarkdownView);
        if (activeView) {
          const editor = activeView.editor;
          const template = `![[${fileName}]]

${result.text}
`;
          editor.replaceSelection(template);
        } else {
          new import_obsidian3.Notice(SUCCESS_MESSAGES.COPIED_TO_CLIPBOARD);
          navigator.clipboard.writeText(result.text);
        }
      } catch (error) {
        processingModal.close();
        console.error(error);
        this.updateStatusBar("Error");
        const errMsg = error.message;
        if (errMsg === "API_UNAUTHORIZED") {
          new import_obsidian3.Notice(ERROR_MESSAGES.API_UNAUTHORIZED, 5e3);
        } else if (errMsg === "API_QUOTA_EXCEEDED") {
          new import_obsidian3.Notice(ERROR_MESSAGES.API_QUOTA_EXCEEDED, 5e3);
        } else {
          new import_obsidian3.Notice("\u274C Transcription failed. Audio saved locally.");
        }
        const activeView = this.app.workspace.getActiveViewOfType(import_obsidian3.MarkdownView);
        if (activeView) {
          activeView.editor.replaceSelection(`![[${fileName}]]
`);
        }
      }
    } catch (error) {
      this.ribbonIconEl.removeClass("voice-writing-recording");
      this.updateStatusBar("Idle");
    }
  }
  updateStatusBar(text) {
    this.statusBarItem.setText(`Mic: ${text}`);
    if (text === "Recording...") {
      this.statusBarItem.addClass("voice-writing-recording");
    } else {
      this.statusBarItem.removeClass("voice-writing-recording");
    }
  }
  onunload() {
  }
  async loadSettings() {
    this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
  }
  async saveSettings() {
    await this.saveData(this.settings);
  }
};
var VoiceWritingSettingTab = class extends import_obsidian3.PluginSettingTab {
  constructor(app, plugin) {
    super(app, plugin);
    this.plugin = plugin;
  }
  display() {
    const { containerEl } = this;
    containerEl.empty();
    containerEl.createEl("h2", { text: "Voice Writing Settings" });
    new import_obsidian3.Setting(containerEl).setName("Service Provider").setDesc("Choose between OpenAI (Best quality) or Groq (Fastest)").addDropdown((drop) => drop.addOption("openai", "OpenAI").addOption("groq", "Groq").setValue(this.plugin.settings.serviceProvider).onChange(async (value) => {
      this.plugin.settings.serviceProvider = value;
      await this.plugin.saveSettings();
      this.display();
    }));
    new import_obsidian3.Setting(containerEl).setName("API Key").setDesc(`Enter your ${this.plugin.settings.serviceProvider === "openai" ? "OpenAI" : "Groq"} API Key`).addText((text) => text.setPlaceholder("sk-...").setValue(this.plugin.settings.apiKey).onChange(async (value) => {
      this.plugin.settings.apiKey = value;
      await this.plugin.saveSettings();
    })).addButton((button) => button.setButtonText("Test API Key").setCta().onClick(async () => {
      button.setButtonText("Testing...");
      button.setDisabled(true);
      const result = await this.plugin.transcriptionService.testApiKey(
        this.plugin.settings.apiKey,
        this.plugin.settings.serviceProvider
      );
      new import_obsidian3.Notice(result.message, result.success ? 3e3 : 5e3);
      if (result.details) {
        console.log("API Test Details:", result.details);
      }
      button.setButtonText("Test API Key");
      button.setDisabled(false);
    }));
    new import_obsidian3.Setting(containerEl).setName("Default Language").setDesc('Language code for transcription (e.g., en, ko, ja). Use "auto" for auto-detection.').addDropdown((drop) => {
      const langs = [
        { code: "auto", name: "Auto Detect" },
        { code: "en", name: "English" },
        { code: "ko", name: "Korean" },
        { code: "ja", name: "Japanese" }
      ];
      langs.forEach((lang) => {
        drop.addOption(lang.code, lang.name);
      });
      drop.setValue(this.plugin.settings.language).onChange(async (value) => {
        this.plugin.settings.language = value;
        await this.plugin.saveSettings();
      });
    });
  }
};
